# This example demonstrates the 'resource' template type, which provides a
# convenient way to create/update/delete any type of kubernetes resources
# in a workflow. The resource template type accepts any k8s manifest
# (including CRDs) and can perform any kubectl action against it (e.g. create,
# apply, delete, patch).
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dyk-k8s-jobs-
spec:
  entrypoint: pi-tmpl
  templates:
  - name: pi-tmpl
    resource:
      action: create
      # successCondition and failureCondition are optional expressions which are
      # evaluated upon every update of the resource. If failureCondition is ever
      # evaluated to true, the step is considered failed. Likewise, if successCondition
      # is ever evaluated to true the step is considered successful. It uses kubernetes
      # label selection syntax and can be applied against any field of the resource
      # (not just labels). Multiple AND conditions can be represented by comma
      # delimited expressions. For more details, see:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
      successCondition: status.applicationState.state == COMPLETED
      failureCondition: status.applicationState.state == FAILED
      manifest: |
        apiVersion: "sparkoperator.k8s.io/v1beta1"
        kind: SparkApplication
        metadata:
          generateName: dyk-test-spark-pi-example-
          namespace: test
        spec:
          type: Scala
          mode: cluster
          image: "gcr.io/spark-operator/spark:v2.4.5"
          imagePullPolicy: Always
          mainClass: org.apache.spark.examples.SparkPi
          mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.11-2.4.5.jar"
          sparkVersion: "2.4.5"
          restartPolicy:
            type: Never
          volumes:
            - name: "test-volume"
              hostPath:
                path: "/tmp"
                type: Directory
          driver:
            cores: 1
            coreLimit: "1200m"
            memory: "512m"
            labels:
              version: 2.4.5
            serviceAccount: test-spark-op-spark
            volumeMounts:
              - name: "test-volume"
                mountPath: "/tmp"
          executor:
            cores: 1
            instances: 1
            memory: "512m"
            labels:
              version: 2.4.5
            volumeMounts:
              - name: "test-volume"
                mountPath: "/tmp"
